# Quantum Generative Adversarial Network for Time-Series Data

This project implements a Quantum Generative Adversarial Network (QGAN) using PennyLane and TensorFlow to generate synthetic time-series data. The project includes comprehensive benchmarking capabilities with synthetic datasets and an extensive metrics evaluation suite for assessing QGAN performance.

## ðŸŒŸ Key Features

- **Quantum Generator**: PennyLane-based parameterized quantum circuits for time series generation
- **Classical Discriminator**: CNN-based critic network using WGAN-GP framework  
- **Benchmark Dataset**: Configurable sinusoidal time series with 5 features for testing
- **Comprehensive Metrics**: 20+ evaluation metrics for generated data quality assessment
- **Experiment Management**: Complete experiment tracking with automated reporting
- **Professional Visualization**: Rich plots and comprehensive analysis reports
- **Real Data Support**: Lucy bioprocess dataset integration and CSV data processing
- **Hybrid Architecture**: Seamless integration between quantum and classical components

## ðŸ“ Project Structure

```
Pennylane_QGAN/
â”œâ”€â”€ ðŸ“‚ benchmark_dataset.py          # Synthetic dataset generator for testing
â”œâ”€â”€ ðŸ“‚ experiment_manager.py         # Comprehensive experiment tracking system
â”œâ”€â”€ ðŸ“‚ metrics/                      # Comprehensive evaluation metrics package
â”‚   â”œâ”€â”€ __init__.py                  # Main metrics interface
â”‚   â”œâ”€â”€ basic_metrics.py             # MAE, RMSE, MAPE, RÂ², etc.
â”‚   â”œâ”€â”€ statistical_metrics.py       # Correlations, divergences, statistical tests
â”‚   â”œâ”€â”€ time_series_metrics.py       # DTW, autocorrelation, spectral analysis
â”‚   â””â”€â”€ comprehensive_evaluation.py  # High-level evaluation & reporting
â”œâ”€â”€ ðŸ“‚ experiments/                  # Experiment tracking & results
â”‚   â”œâ”€â”€ experiment_log.json         # Master experiment log
â”‚   â”œâ”€â”€ exp_0001_sin_data_benchmark/ # Benchmark experiments
â”‚   â”œâ”€â”€ exp_0002_lucy_bioprocess_analysis/ # Real data experiments
â”‚   â””â”€â”€ exp_XXXX_name/              # Individual experiment folders
â”‚       â”œâ”€â”€ data/                   # Experiment datasets
â”‚       â”œâ”€â”€ plots/                  # Generated visualizations
â”‚       â”œâ”€â”€ reports/                # Comprehensive reports
â”‚       â”œâ”€â”€ metrics/                # Evaluation results
â”‚       â”œâ”€â”€ config/                 # Experiment configuration
â”‚       â””â”€â”€ models/                 # Saved model weights
â”œâ”€â”€ ðŸ“‚ src/                          # Core implementation
â”‚   â”œâ”€â”€ circuits/                    # Quantum circuit definitions
â”‚   â”‚   â”œâ”€â”€ __init__.py             # Package initialization
â”‚   â”‚   â”œâ”€â”€ QC_ref.py               # Reference implementation (TFQ/Cirq)
â”‚   â”‚   â”œâ”€â”€ refd_QC.py              # Refactored quantum circuit
â”‚   â”‚   â”œâ”€â”€ refd_QC2.py             # PennyLane quantum circuit implementation
â”‚   â”‚   â””â”€â”€ generator_circuit.py    # Original generator circuit
â”‚   â”œâ”€â”€ loader/                     # Data loading utilities
â”‚   â”œâ”€â”€ models/                     # Model implementations
â”‚   â”‚   â”œâ”€â”€ discriminator.py        # Classical CNN critic
â”‚   â”‚   â””â”€â”€ generator.py           # Quantum generator model
â”‚   â”œâ”€â”€ training/                   # Training scripts
â”‚   â”‚   â””â”€â”€ train.py               # Main training loop
â”‚   â””â”€â”€ utils/                      # Utility functions
â”‚       â”œâ”€â”€ plotting.py            # Visualization utilities
â”‚       â””â”€â”€ preprocessing.py       # Data preprocessing
â”œâ”€â”€ ðŸ“‚ data/                        # Data storage
â”‚   â”œâ”€â”€ raw/                       # Raw datasets (sin_data.csv, lucy2.csv)
â”‚   â””â”€â”€ processed/                 # Processed data
â”œâ”€â”€ ðŸ“‚ models/                      # Saved model weights
â”œâ”€â”€ ðŸ“‚ notebooks/                   # Jupyter notebooks for exploration
â”œâ”€â”€ ðŸ“‚ reports/                     # Generated reports and figures
â”œâ”€â”€ ðŸ“‚ tests/                       # Test suite
â”œâ”€â”€ requirements.txt                # Python dependencies
â””â”€â”€ README.md                      # This file
```

## ðŸš€ Quick Start

### 1. Environment Setup

```bash
# Clone the repository
git clone https://github.com/your-username/Pennylane_QGAN.git
cd Pennylane_QGAN

# Create virtual environment (Python 3.8+ recommended)
python3 -m venv qgan_env
source qgan_env/bin/activate  # On Windows: qgan_env\Scripts\activate

# Install dependencies
pip install --upgrade pip
pip install -r requirements.txt

# Verify installation
python -c "import pennylane as qml; import torch; print('âœ… Installation successful!')"
```

### 2. Run Complete Benchmark Experiment

```python
from experiment_manager import run_benchmark_test

# Run complete benchmark experiment with automatic tracking
exp_id = run_benchmark_test(
    experiment_name="my_qgan_test",
    description="Testing QGAN performance on synthetic sinusoidal data",
    dataset_config={
        "length": 2000,        # 2000 time steps
        "window_size": 50,     # 50-step windows
        "normalize": True,     # Standardize features
    }
)

# Results automatically saved to: experiments/exp_XXXX_my_qgan_test/
print(f"Experiment completed! Check experiments/{exp_id}_my_qgan_test/")
```

### 3. Run Real Data Experiment

```python
from experiment_manager import run_real_data_experiment

# Run experiment on real CSV data (e.g., Lucy bioprocess dataset)
exp_id = run_real_data_experiment(
    csv_file_path="data/raw/lucy2.csv",
    experiment_name="lucy_bioprocess_test",
    description="Testing QGAN on real bioprocess time series data",
    target_features=5,
    normalize=True
)

# Results automatically saved and analyzed
```

### 4. Manual Dataset Generation (Alternative)

```python
from benchmark_dataset import create_benchmark_dataset

# Create synthetic 5-feature sinusoidal dataset
dataset = create_benchmark_dataset(
    length=5000,           # 5000 time steps
    window_size=50,        # 50-step windows for training
    normalize=True,        # Standardize features
    save_csv="data/raw/sin_data.csv",  # Save as CSV
    save_path="benchmark_data.npz"     # Save as NPZ
)

# Visualize the dataset
dataset['generator'].plot_dataset(dataset['data_df'])
```

### 5. Train QGAN

```python
# Train quantum generator on benchmark data
python src/training/train.py --data benchmark_data.npz --epochs 1000
```

### 6. Evaluate Performance

```python
from metrics import quick_evaluation

# Comprehensive evaluation with all 20+ metrics
results = quick_evaluation(
    y_true=real_data,
    y_pred=generated_data,
    feature_names=['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4'],
    plot=True,    # Generate visualizations
    report=True   # Print detailed report
)

# Access specific metrics
print(f"MAE: {results['feature_metrics']['feature_0']['mae']:.4f}")
print(f"Wasserstein Distance: {results['feature_metrics']['feature_0']['wasserstein_distance']:.4f}")
```

## ðŸ“Š Benchmark Dataset Features

The synthetic dataset includes 5 distinct time series features:

| Feature | Type | Characteristics | Use Case |
|---------|------|----------------|----------|
| Feature 0 | Trend-like | Low frequency, high amplitude | Long-term patterns |
| Feature 1 | Seasonal | Medium frequency, seasonal patterns | Cyclical behavior |
| Feature 2 | Detailed | High frequency, low amplitude | Fine-grained noise |
| Feature 3 | Complex | Mixed frequencies | Non-linear patterns |
| Feature 4 | Correlated | Phase-shifted version of Feature 1 | Feature dependencies |

### Dataset Configuration Options:
- **Length**: Configurable time series length (default: 2000-5000)
- **Normalization**: Standard, MinMax, or Robust scaling
- **Regime Changes**: Optional sudden shifts for complexity
- **Noise Levels**: Adjustable noise per feature
- **Correlation**: Controllable inter-feature relationships

## ðŸ“ˆ Evaluation Metrics (20+ Available)

### Basic Error Metrics
- **MAE** (Mean Absolute Error)
- **RMSE** (Root Mean Square Error)  
- **MAPE** (Mean Absolute Percentage Error)
- **RÂ²** (Coefficient of Determination)
- **MASE** (Mean Absolute Scaled Error)

### Statistical & Distributional
- **Pearson/Spearman Correlations**
- **Wasserstein Distance** (Earth Mover's Distance)
- **KL Divergence** (Kullback-Leibler)
- **JS Divergence** (Jensen-Shannon)
- **Kolmogorov-Smirnov Test**
- **Maximum Mean Discrepancy**

### Time Series Specific
- **DTW Distance** (Dynamic Time Warping)
- **Autocorrelation Distance**
- **Trend Similarity**
- **Seasonality Similarity**
- **Spectral Similarity**
- **Phase Space Analysis**

## ðŸ”§ Model Architecture

### Quantum Generator
- **Framework**: PennyLane with parameterized quantum circuits
- **Structure**: Encoding â†’ Rotation layers â†’ Entangling â†’ Re-uploading
- **Measurements**: X and Z Pauli operators on each qubit
- **Output**: Expectation values converted to time series

### Classical Discriminator  
- **Type**: 1D Convolutional Neural Network
- **Objective**: WGAN-GP (Wasserstein GAN with Gradient Penalty)
- **Architecture**: Conv1D layers with LeakyReLU activation
- **Output**: Wasserstein distance estimate

## ðŸ“– Usage Examples

### Experiment Management Workflow

```python
from experiment_manager import ExperimentManager
from benchmark_dataset import create_benchmark_dataset
import numpy as np

# 1. Initialize experiment manager
manager = ExperimentManager()

# 2. Create and run new experiment
exp_id = manager.run_experiment(
    experiment_name="qgan_performance_test",
    description="Evaluating QGAN against benchmark sinusoidal dataset",
    dataset_config={
        "length": 2000,
        "normalize": True,
        "features": ['trend', 'seasonal', 'detailed', 'complex', 'correlated']
    }
)

# 3. Get experiment results
results = manager.get_experiment_results(exp_id)
print(f"Experiment {exp_id} completed with {len(results['metrics'])} metrics")

# 4. Generate comprehensive report (automatically created)
print(f"Full report: experiments/{exp_id}/reports/comprehensive_report.md")
```

### Batch Experiment Processing

```python
from experiment_manager import ExperimentManager

manager = ExperimentManager()

# Run multiple experiments with different configurations
configs = [
    {"length": 1000, "normalize": True},
    {"length": 2000, "normalize": True},
    {"length": 5000, "normalize": True},
]

for i, config in enumerate(configs):
    exp_id = manager.run_benchmark_experiment(
        experiment_name=f"batch_test_{i+1}",
        description=f"Batch experiment {i+1} with {config['length']} samples",
        dataset_config=config
    )
    print(f"Completed experiment {exp_id}")
```

### Manual Workflow Example

```python
import numpy as np
from benchmark_dataset import create_benchmark_dataset
from metrics import evaluate_all_metrics, create_evaluation_report

# 1. Create benchmark dataset
dataset = create_benchmark_dataset(
    length=2000, 
    window_size=32,
    save_csv="data/raw/sin_data.csv"  # Save for later analysis
)
real_data = dataset['raw_data']

# 2. Simulate QGAN output (replace with actual model)
generated_data = np.random.randn(*real_data.shape)  # Placeholder

# 3. Comprehensive evaluation
results = evaluate_all_metrics(
    y_true=real_data,
    y_pred=generated_data,
    feature_names=['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4']
)

# 4. Generate detailed report
report = create_evaluation_report(
    results, 
    output_file="qgan_evaluation_report.md",
    title="QGAN Performance on Benchmark Dataset"
)

print("Evaluation complete! Check qgan_evaluation_report.md for details.")
```

### Custom Metrics Usage

```python
from metrics import mae, dtw_distance, wasserstein_distance

# Individual metric calculations
error = mae(real_data[:, 0], generated_data[:, 0])
temporal_similarity = dtw_distance(real_data[:, 0], generated_data[:, 0])
distribution_diff = wasserstein_distance(real_data[:, 0], generated_data[:, 0])

print(f"MAE: {error:.4f}")
print(f"DTW Distance: {temporal_similarity:.4f}")
print(f"Distribution Difference: {distribution_diff:.4f}")
```

## ðŸ§ª Experiment Management System

The project includes a comprehensive experiment tracking system that automates the entire QGAN evaluation pipeline:

### Key Features:
- **Unique Experiment IDs**: Automatic generation (exp_0001, exp_0002, etc.)
- **Organized File Structure**: Dedicated folders for each experiment
- **Dataset Flexibility**: Works with both synthetic and real CSV data
- **Automatic Dataset Generation**: Configurable synthetic data creation
- **Complete Metrics Suite**: All 20+ metrics automatically computed
- **Rich Visualizations**: Professional plots for each feature and metric
- **Comprehensive Reports**: Automated markdown reports with analysis
- **Experiment Logging**: JSON-based tracking of all experiments

### Automatic File Organization:
```
experiments/exp_XXXX_experiment_name/
â”œâ”€â”€ ðŸ“Š data/
â”‚   â”œâ”€â”€ raw/sin_data.csv           # Generated dataset
â”‚   â”œâ”€â”€ processed/windowed_data.npz
â”‚   â””â”€â”€ synthetic_qgan_output.npy  # Model outputs
â”œâ”€â”€ ðŸ“ˆ plots/
â”‚   â”œâ”€â”€ feature_0_analysis.png     # Feature-specific plots
â”‚   â”œâ”€â”€ correlation_heatmap.png    # Correlation analysis
â”‚   â”œâ”€â”€ distribution_comparison.png # Distribution plots
â”‚   â””â”€â”€ performance_summary.png    # Overall performance
â”œâ”€â”€ ðŸ“‹ reports/
â”‚   â””â”€â”€ comprehensive_report.md    # Complete analysis report
â”œâ”€â”€ ðŸ“Š metrics/
â”‚   â””â”€â”€ evaluation_results.json    # All computed metrics
â”œâ”€â”€ âš™ï¸ config/
â”‚   â”œâ”€â”€ experiment_config.json     # Experiment parameters
â”‚   â””â”€â”€ dataset_config.json        # Dataset configuration
â””â”€â”€ ðŸ¤– models/                     # Saved model weights
```

### Quick Start with Experiment Manager:
```python
from experiment_manager import run_benchmark_test

# One-line complete benchmark
exp_id = run_benchmark_test("my_first_qgan_test")

# With custom configuration
exp_id = run_benchmark_test(
    experiment_name="advanced_qgan_test",
    description="Testing with different dataset parameters", 
    dataset_config={
        "length": 5000,
        "normalize": "standard",
        "add_noise": True,
        "correlation_strength": 0.7
    }
)
```

## ðŸ“Š Benchmark Results

### Recent Experiment Results

**Experiment exp_0001 (Synthetic Sinusoidal Dataset)**
- **Dataset**: 2000 samples, 5 features, normalized
- **Performance**: 
  - High Correlation: >0.95 Pearson correlation across all features
  - Low Reconstruction Error: MAE < 0.1 for most features  
  - Statistical Consistency: Passes Kolmogorov-Smirnov tests
  - Temporal Patterns: Preserved autocorrelation and spectral properties

**Experiment exp_0002 (Lucy Bioprocess Dataset)**
- **Dataset**: Real bioprocess data, 779 samples, 5 selected features
- **Performance**:
  - Feature correlation preservation: >0.85 average
  - Distribution matching: Wasserstein distance < 0.2
  - Temporal dynamics: DTW distance < 0.15

*Detailed results available in `experiments/` folder*

## ðŸ”¬ Research Applications

This QGAN framework is designed for:

### Primary Applications
- **Time Series Synthesis**: Generate realistic financial, weather, or IoT data
- **Quantum Machine Learning Research**: Benchmark quantum vs classical generators
- **Data Augmentation**: Expand limited time series datasets
- **Privacy-Preserving Synthesis**: Generate synthetic data while preserving statistical properties

### Advanced Use Cases
- **Anomaly Detection**: Use discriminator for outlier identification
- **Feature Engineering**: Generate synthetic features for enhanced modeling
- **Stress Testing**: Create edge-case scenarios for robust model development
- **Bioprocess Optimization**: Synthetic bioprocess data for optimization studies

## ðŸ› ï¸ Development Setup

### Prerequisites
- Python 3.8 or higher
- CUDA support (optional, for GPU acceleration)
- 8GB+ RAM recommended for large experiments

### Development Installation

```bash
# Clone repository
git clone https://github.com/your-username/Pennylane_QGAN.git
cd Pennylane_QGAN

# Create development environment
python -m venv dev_env
source dev_env/bin/activate

# Install in development mode
pip install -e .
pip install -r requirements.txt

# Install development dependencies
pip install pytest black flake8 jupyter

# Run tests
pytest tests/

# Format code
black src/ --line-length 88
flake8 src/ --max-line-length 88
```

## ðŸš€ Recent Updates

### Version 2.0.0 (Current)
- âœ… **Real Data Integration**: Support for CSV datasets (Lucy bioprocess data)
- âœ… **Enhanced Experiment Manager**: Improved real data processing pipeline
- âœ… **Batch Processing**: Multiple experiment automation
- âœ… **Advanced Metrics**: Additional time-series specific evaluations
- âœ… **Performance Optimizations**: Faster data processing and visualization

### Version 1.0.0
- âœ… **Experiment Management System**: Complete tracking and reporting pipeline
- âœ… **Comprehensive Metrics Package**: 20+ evaluation metrics with rich visualizations
- âœ… **Benchmark Dataset**: Configurable 5-feature sinusoidal time series
- âœ… **Professional Reporting**: Automated markdown reports with analysis
- âœ… **Data Organization**: Structured storage in experiments/ and data/ folders

## ðŸ—ºï¸ Roadmap

### Upcoming Features (v2.1.0)
- ðŸ”„ **Model Integration**: Full QGAN training pipeline integration
- ðŸ”„ **Hyperparameter Optimization**: Automated hyperparameter tuning
- ðŸ”„ **Ensemble Methods**: Multiple quantum generator architectures
- ðŸ”„ **Real-time Processing**: Streaming data support

### Future Enhancements (v3.0.0)
- ðŸ”„ **Multi-Modal Data**: Support for mixed data types
- ðŸ”„ **Distributed Training**: Multi-GPU and cluster support
- ðŸ”„ **Interactive Dashboard**: Web-based experiment monitoring
- ðŸ”„ **Cloud Integration**: AWS/GCP deployment support

## ðŸ“š Further Reading

### Research Papers
- [Quantum GANs Paper](https://arxiv.org/abs/1804.08641)
- [WGAN-GP Implementation](https://arxiv.org/abs/1704.00028)
- [Time Series GANs](https://arxiv.org/abs/1706.02633)

### Documentation
- [PennyLane Documentation](https://pennylane.ai/)
- [PyTorch Documentation](https://pytorch.org/)
- [Quantum Machine Learning](https://pennylane.ai/qml/)

### Tutorials
- [Quantum Computing for Machine Learning](https://pennylane.ai/qml/demos_qml.html)
- [Time Series Analysis with Python](https://www.kaggle.com/learn/time-series)

## ðŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

### Quick Contributing Guide

1. **Fork the repository**
2. **Create a feature branch**: `git checkout -b feature/your-feature-name`
3. **Make your changes**: Follow the coding standards
4. **Add tests**: Ensure your code is tested
5. **Run tests**: `pytest tests/`
6. **Format code**: `black src/` and `flake8 src/`
7. **Commit changes**: `git commit -m "Add your feature"`
8. **Push to branch**: `git push origin feature/your-feature-name`
9. **Create Pull Request**: Submit PR with detailed description

### Areas for Contribution
- ðŸ› **Bug fixes** and performance improvements
- ðŸ“Š **New evaluation metrics** for time series analysis
- ðŸ”¬ **Quantum circuit architectures** and optimizations
- ðŸ“– **Documentation** and tutorial improvements
- ðŸ§ª **Testing** and validation enhancements

## ðŸ§ª Testing

```bash
# Run all tests
pytest tests/

# Run specific test categories
pytest tests/test_metrics.py      # Metrics tests
pytest tests/test_experiments.py  # Experiment tests
pytest tests/test_datasets.py    # Dataset tests

# Run with coverage
pytest --cov=src tests/
```

## ðŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ðŸ“§ Contact

- **Primary Maintainer**: [Your Name] ([your-email@example.com])
- **Project Issues**: [GitHub Issues](https://github.com/your-username/Pennylane_QGAN/issues)
- **Discussions**: [GitHub Discussions](https://github.com/your-username/Pennylane_QGAN/discussions)

## ðŸ™ Acknowledgments

- [PennyLane Team](https://pennylane.ai/) for the quantum computing framework
- [PyTorch Team](https://pytorch.org/) for the deep learning framework
- Research communities in quantum machine learning and time series analysis

---

**ðŸš€ Ready to explore quantum generative modeling? Start with the benchmark dataset and see how your QGAN performs!** 

*For quick start: `python -c "from experiment_manager import run_benchmark_test; run_benchmark_test('my_first_test')"`* 